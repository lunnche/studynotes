## Machine Learning

machine learning â‰ˆ looking for function

* Speech Recognition

![Screen Shot 2021-12-20 at 2.11.16 PM](https://raw.githubusercontent.com/lunnche/picgo-image/main/Screen%20Shot%202021-12-20%20at%202.11.16%20PM.png)

* Image Recognition

![Screen Shot 2021-12-20 at 2.11.42 PM](https://raw.githubusercontent.com/lunnche/picgo-image/main/Screen%20Shot%202021-12-20%20at%202.11.42%20PM.png)

* Playing Go

![Screen Shot 2021-12-20 at 2.12.08 PM](https://raw.githubusercontent.com/lunnche/picgo-image/main/Screen%20Shot%202021-12-20%20at%202.12.08%20PM.png)

### Different types of Functions
Regression:The function outputs a scalar ç”¨äºè¿ç»­å€¼   

Classification:Given options(classes),the function outputs the correct one ç”¨äºç¦»æ•£å€¼  

alphaGoå…¶å®ä¹Ÿæ˜¯åˆ†ç±»é—®é¢˜ è¾“å…¥æ£‹å±€ï¼Œè¾“å‡ºä»19Ã—19ä¸ªåˆ†ç±»ï¼ˆä½ç½®ï¼‰ä¸­é€‰ä¸€ä¸ª

é™¤äº†regressionå’Œclassificationï¼Œè¿˜æœ‰strctured learning,å³æœºå™¨å­¦ä¹ é™¤äº†åˆ†ç±»ï¼Œè¾“å‡ºä¸€ä¸ªæ•°å€¼ä¹‹å¤–ï¼Œè¿˜å¯ä»¥åˆ›é€ ä¸€ä¸ªæœ‰ç»“æ„çš„ç‰©ä»¶ã€‚
ä¾‹å¦‚ ç”»å›¾ï¼Œå†™æ–‡ç«  è¿™ç§è®©æœºå™¨äº§ç”Ÿæœ‰ç»“æ„çš„ä¸œè¥¿çš„é—®é¢˜å°±å«structured learning
,å³è®©æœºå™¨å­¦ä¼šåˆ›é€ ã€‚

ä¸€ä¸ªä¾‹å­ youtubeè¿‡å»çš„æ•°æ®ï¼Œé¢„æµ‹æ˜å¤©çš„ç‚¹é˜…æ€»äººæ•°  

åˆ†ä¸‰ä¸ªæ­¥éª¤ï¼š

## 1
çŒœæµ‹ä¸€ä¸ªå«æœ‰æœªçŸ¥å‚æ•°çš„å‡½æ•° ï¼ˆå¾…å®šç³»æ•°æ³•ï¼‰ è¿™ä¸ªçŒœæµ‹æ˜¯æ¥æºäºå¯¹é—®é¢˜æœ¬è´¨ä¸Šçš„äº†è§£ï¼ˆdomain knowledgeï¼‰  
$$
    y=b+wx_1
$$

yæ˜¯è¦é¢„æµ‹çš„æœªæ¥çš„ç‚¹é˜…é‡    xæ˜¯å·²çŸ¥çš„ç‚¹é˜…é‡
    bå’Œwæ˜¯æœªçŸ¥çš„å‚æ•°ï¼Œè¦ä»æ•°æ®ä¸­å­¦ä¹ å¾—æ¥
å¸¦æœ‰æœªçŸ¥å‚æ•°çš„functionå°±å«åšmodel

$x_1$æ˜¯å·²çŸ¥çš„youtubeåå°çš„èµ„è®¯ï¼Œå«åšfeature,wå«åšweightï¼Œbå«åšbias

## 2 
Define Loss from Training Data

Loss is a function of parameters  L(b,w)
Loss : how good a set of values is .

çœŸå®å€¼ï¼Œæ­£ç¡®çš„æ•°å€¼å«label   æ€ä¹ˆè®¡ç®—Lossï¼Ÿç»™å®šä¸€ç»„ï¼ˆb,wï¼‰ï¼Œæ ¹æ®è®­ç»ƒæ•°æ®ï¼Œè®¡ç®—æ‰€æœ‰é¢„æµ‹å€¼å’ŒçœŸå®å€¼çš„åå·®çš„æ€»å’Œæ±‚å¹³å‡

$$
Loss:L=\frac{1}{N}\sum_{n}{e_n}
$$
Lè¶Šå¤§ï¼Œä»£è¡¨è¿™ä¸€ç»„å‚æ•°è¶Šä¸å¥½ï¼Œeå°±æ˜¯è®¡ç®—ä¼°ç®—å€¼å’Œå®æµ‹å€¼ä¹‹é—´çš„å·®è·:  

***

$$
e=\left|y-\widehat{y}\right|        
$$
<center>L is mean absolute error (MAE)</center>  

***

$$
e=(y-\widehat{y})^2
$$
<center>L is mean square error (MSE)</center>
***

MSEå’ŒMAEæœ‰å¾®å¦™çš„å·®åˆ«ï¼Œå…·ä½“é€‰å“ªä¸ªåº”æ ¹æ®å…·ä½“é—®é¢˜åˆ†æï¼Œè¿™é‡Œé€‰MAE
MSEä¹Ÿå¯ä»¥ï¼Œä½œä¸šé‡Œç”¨MSE


æœ‰ä¸€äº›ä»»åŠ¡ï¼š
if y and $\widehat{y}$ are both probability distributions æ¦‚ç‡åˆ†å¸ƒ
æ­¤æ—¶å¯èƒ½ä¼šé€‰æ‹©Cross-entropy

![Screen Shot 2021-12-24 at 9.10.01 AM](https://raw.githubusercontent.com/lunnche/picgo-image/main/Screen%20Shot%202021-12-24%20at%209.10.01%20AM.png)
<center>ä¸Šå›¾ä¸ºLosså‡½æ•°å›¾åƒï¼Œæ¨ªåæ ‡wï¼Œçºµåæ ‡b</center>
è¿™ç§ç­‰é«˜çº¿å›¾å«error surface

## 3
Optimization  

$$
w^*,b^* = \mathop{\arg\min}\limits_{w,b} L
$$

è¿™ä¸ªæœ€ä¼˜åŒ–é—®é¢˜å¯è¡¨è¿°ä¸ºï¼šæ‰¾ä¸€ä¸ªæœ€ä¼˜çš„w,bå€¼ç»„ï¼Œå¯ä»¥è®©Lå€¼æœ€å°ï¼Œè¿™ä¸ªå…·ä½“çš„w,bå€¼ï¼Œè®°ä¸º$w^*$,$b^*$
è¦æ€ä¹ˆæ‰¾å‡ºè¿™ä¸ª$w^*$,$b^*$å€¼å‘¢ï¼Œç”¨Gradient Descentæ–¹æ³• æ¢¯åº¦ä¸‹é™

è¿™ä¸ªGradient Descentæ–¹æ³•å…·ä½“æ€ä¹ˆåšå‘¢ï¼Œä¸ºè¡¨è¿°æ–¹ä¾¿ï¼Œå…ˆå‡è®¾åªæœ‰ä¸€ä¸ªæœªçŸ¥å‚æ•°wï¼š
$$
w^*=\mathop{\arg\min}\limits_{w}L
$$

![Screen Shot 2021-12-26 at 6.03.42 PM](https://raw.githubusercontent.com/lunnche/picgo-image/main/Screen%20Shot%202021-12-26%20at%206.03.42%20PM.png)
è¿™æ¡æ›²çº¿å°±æ˜¯error surfaceçš„äºŒç»´ç‰ˆ


æ€ä¹ˆæ‰¾åˆ°è¿™ä¸ªè®©Lå€¼æœ€å°çš„wå‘¢ï¼Œå³Gradient Descentçš„æ­¥éª¤ï¼š

**1 (Randomly)Pick an initial value**  
   $w^0$ï¼ˆæœ‰ä¸€äº›æ–¹æ³•å¯ä»¥ç»™æˆ‘ä»¬ä¸€ä¸ªæ¯”è¾ƒå¥½çš„åˆå§‹å€¼ï¼Œä½†è¿™é‡Œå…ˆæ•´ä¸ªéšæœºçš„ï¼‰

**2 compute**
   $\frac{\partial{L}}{\partial{w}}|_{w=w^0}$   

   è®¡ç®—w=$w^0$æ—¶ï¼Œwè¿™ä¸ªå‚æ•°å¯¹Lossçš„å¾®åˆ†,å³è®¡ç®—åœ¨$w_0$è¿™ä¸€ç‚¹ï¼Œerror surfaceåˆ‡çº¿çš„æ–œç‡ï¼Œè‹¥åˆ‡çº¿çš„æ–œç‡æ˜¯è´Ÿçš„ï¼Œå³å·¦è¾¹é«˜å³è¾¹ä½ï¼Œé‚£å°±æŠŠwå€¼å˜å¤§ï¼Œå°±å¯ä»¥è®©Losså˜å°ã€‚
    åä¹‹å‡å°wã€‚
    å¢åŠ æˆ–å‡å°wï¼Œæ­¥å¹…å¤šå¤§å‘¢ï¼Œå–å†³äºä¸¤ä»¶äº‹ï¼Œ1 æ–œç‡ 2 $\eta$
    $$
    w^1\leftarrow w^0-\eta\frac{\partial{L}}{\partial{w}}|_{w=w^0}
    $$

$\eta$: learning rate
learning rateæ˜¯è‡ªå·±è®¾å®šçš„ï¼Œåƒlearning rateè¿™ç§åœ¨æœºå™¨å­¦ä¹ ä¸­éœ€è¦è‡ªå·±è®¾å®šçš„ä¸œè¥¿å«åšhyperparameters

ä¹‹å‰è¯´åšæœºå™¨å­¦ä¹ ç¬¬ä¸€æ­¥ä¸­åŒ…å«æœªçŸ¥å‚æ•°ï¼Œè¿™äº›å‚æ•°æ˜¯æœºå™¨è‡ªå·±æ‰¾å‡ºæ¥çš„  

ä¸ºä»€ä¹ˆLosså¯ä»¥æ˜¯è´Ÿçš„ï¼ŒLossæ˜¯ä¼°æµ‹çš„å€¼å’Œæ­£ç¡®çš„å€¼ä¹‹å·®çš„ç»å¯¹å€¼ï¼ŒæŒ‰ç†ä¸å¯èƒ½æ˜¯è´Ÿï¼Œä½†æ˜¯Lossè¿™ä¸ªfunctionæ˜¯ä½ è‡ªå·±å†³å®šçš„ï¼Œæ¯”å¦‚æˆ‘å®šä¹‰ä¸€ä¸ªLoss=ç»å¯¹å€¼-100ï¼Œä¸Šå›¾çš„Lossåªæ˜¯éšä¾¿çç”»çš„ï¼Œæ²¡æœ‰ä»»ä½•å®é™…æ„ä¹‰ï¼Œè‹¥æŒ‰ä¸€èˆ¬é—®é¢˜ä¸­Lossä¸ºç»å¯¹å€¼çš„å®šä¹‰ï¼Œåˆ™ä¸å¯èƒ½å‡ºç°è´Ÿå€¼  

**3 Update w iteratively** ä»€ä¹ˆæ—¶å€™åœä¸‹æ¥å‘¢ ä¸¤ç§æƒ…å†µ 1 ä½ å¤±å»è€å¿ƒ è®¾å®šå‚æ•°æ›´æ–°å¤šå°‘æ¬¡ååœä¸‹ï¼Œè¿™ä¸ªå¤šå°‘æ¬¡ä¹Ÿæ˜¯ä¸ªhyperparameterï¼Œ2 å¾®åˆ†é‚£ä¸€é¡¹ç®—å‡ºæ¥æ˜¯0

å› æ­¤ï¼Œgradient descentæ–¹æ³•æœ‰ä¸€ä¸ªå·¨å¤§çš„é—®é¢˜ï¼Œé‚£å°±æ˜¯æˆ‘ä»¬æ²¡æœ‰æ‰¾åˆ°é‚£ä¸ªæœ€å¥½çš„è§£ï¼Œæ¢¯åº¦ä¸‹é™æ‰¾åˆ°çš„æ˜¯å±€éƒ¨æœ€ä¼˜(local minima)ï¼Œè€Œéå…¨å±€æœ€ä¼˜(global minima)

![Screen Shot 2021-12-26 at 6.24.01 PM](https://raw.githubusercontent.com/lunnche/picgo-image/main/Screen%20Shot%202021-12-26%20at%206.24.01%20PM.png)

æ‰€ä»¥æœ‰äººè¯´gradient descentä¸æ˜¯ä¸ªå¥½æ–¹æ³•ï¼Œè¿™ä¸ªæ–¹æ³•æœ‰local minimaçš„é—®é¢˜ï¼Œæ²¡æœ‰åŠæ³•çœŸçš„æ‰¾åˆ°global minimaã€‚ä½†è¿™å…¶å®åªæ˜¯å¹»è§‰è€Œå·²ï¼Œå‡è®¾ä½ æœ‰åšè¿‡æ·±åº¦å­¦ä¹ ç›¸å…³çš„äº‹æƒ…ï¼Œå‡è®¾ä½ æœ‰è‡ªå·±è®­ç»ƒnetworkï¼Œè‡ªå·±åšè¿‡Gradient Descentç»éªŒçš„è¯ï¼Œå…¶å®local minimaæ˜¯ä¸€ä¸ªå‡é—®é¢˜ï¼Œæˆ‘ä»¬åœ¨åšGradient Descentçš„æ—¶å€™ï¼ŒçœŸæ­£é¢å¯¹çš„éš¾é¢˜ä¸æ˜¯local minimaï¼Œåˆ°åº•æ˜¯ä»€ä¹ˆï¼Œä¹‹åä¼šè®²ã€‚

## æœ‰ä¸¤ä¸ªå‚æ•°çš„æƒ…å†µ

$$
w^*,b^* = \mathop{\arg\min}_{w,b} L
$$

* (Randomly)Pick initial values $w^0,b^0$  
* Compute  
$$
\frac{\partial{L}}{\partial{w}}|_{w=w^0,b=b^0}
$$
$$
\frac{\partial{L}}{\partial{b}}|_{w=w^0,b=b^0}
$$

åˆ†åˆ«è®¡ç®—wå¯¹Lossçš„å¾®åˆ†ï¼Œbå¯¹Lossçš„å¾®åˆ†  

$$
w^1 \leftarrow w^0 - \eta \frac{\partial{L}}{\partial{w}}|_{w=w^0,b=b^0}
$$
$$
b^1 \leftarrow b^0 - \eta \frac{\partial{L}}{\partial{b}}|_{w=w^0,b=b^0}
$$

å¦‚ä¸Šï¼Œ$w^0$ å‡å» learning rate ä¹˜ä¸Š å¾®åˆ†çš„ç»“æœ å¾—åˆ° $w^1$  

é‚£ä¹ˆè¿™ä¸ªå¾®åˆ†è¦æ€ä¹ˆç®—å‘¢ï¼Œå…¶å® Can be done in one line in most deep learning frameworks

* Update w and b interatively  

ä¸ºä»€ä¹ˆåœ¨è¿™ä¸ªæ–¹å‘å‰é¢è¦åŠ ä¸Šè´Ÿå·ï¼Ÿ  
å› ä¸ºå¦‚æœç®—å‡ºæ¥çš„å¾®åˆ†æ˜¯è´Ÿçš„ï¼Œè¯´æ˜å³ä¾§çš„Lå°ï¼Œå› æ­¤wè¦å¢å¤§ï¼ˆå¾€å³ç§»åŠ¨ï¼‰ï¼ŒåŠ ä¸Šè´Ÿå·ä½ç§»å°±ä¸ºæ­£äº†ã€‚

![Screen Shot 2021-12-26 at 8.10.37 PM](https://raw.githubusercontent.com/lunnche/picgo-image/main/Screen%20Shot%202021-12-26%20at%208.10.37%20PM.png)

è‹¥
$$
w^*=0.97,b^*=0.1k\\
L(w^*,b^*)=0.48k
$$
è¯´æ˜å•¥ï¼š
å–wä¸º0.97ï¼Œbä¸º0.1k æ•ˆæœæœ€å¥½ï¼Œå³å…¶å®x1å’Œyæ˜¯æ¥è¿‘çš„ï¼Œæ‰€ä»¥å½“weightå–æ¥è¿‘1ï¼Œbiaså–å°å€¼æ—¶ï¼Œæ•ˆæœè¾ƒå¥½ï¼ŒLè¡¨æ˜é¢„æµ‹å’Œå®é™…ç‚¹é˜…é‡çš„å¹³å‡åå·®åœ¨500äººå·¦å³ã€‚

æ€»ç»“ï¼š
Machine Learning is so simple:
* Step1: function with unkown
* Step2: define loss from training data 
    æ³¨æ„ä»€ä¹ˆ: 
    $L$ :è®­ç»ƒæ•°æ®çš„Loss 
    $L^{'}$ :æœªçŸ¥æ•°æ®çš„Loss
* Step3: optimization

ç„¶åï¼Œä¸Šä¾‹çš„ç»“æœæ˜¯æœ€ä»¤äººæ»¡æ„çš„ç»“æœå—ï¼š
$y=0.1k+0.97x_1$ achieves the smallest loss $L=0.48k$ on data of 2017-2020(training data)

ä¹Ÿè®¸ä¸æ˜¯ï¼Œå› ä¸ºä¸Šè¿°ä¸‰éƒ¨ç»Ÿç§°ä¸ºè®­ç»ƒ(training)ï¼Œå³åœ¨å·²çŸ¥çš„èµ„æ–™ä¸Šå»è®¡ç®—lossï¼Œå…¶å®åªæ˜¯åœ¨è‡ªhighè€Œå·²,å³å‡è£…è‡ªå·±ä¸çŸ¥é“éš”å¤©çš„ç‚¹é˜…é‡ï¼Œæ‹¿æ±‚å‡ºçš„å‡½æ•°yæ¥é¢„æµ‹ï¼Œèƒ½å¾—åˆ°0.48kçš„Lossï¼Œä½†æˆ‘ä»¬çœŸæ­£åœ¨æ„çš„ä¸æ˜¯è¿‡å»å·²ç»çŸ¥é“çš„ä¸œè¥¿ï¼Œè€Œæ˜¯æœªæ¥æœªçŸ¥çš„è§‚çœ‹æ¬¡æ•°

How about data of 2021 (unseen during training)?
$$
L'=0.58k
$$

 ![Screen Shot 2021-12-29 at 3.37.40 PM](https://raw.githubusercontent.com/lunnche/picgo-image/main/Screen%20Shot%202021-12-29%20at%203.37.40%20PM.png)

å¯æ˜¯åŒ–åå¦‚ä¸Šå›¾æ‰€ç¤ºï¼š
å‘ç°æ¯åˆ°å‘¨äº”ã€å‘¨å…­å°±æ²¡äººå­¦æœºå™¨å­¦ä¹ ï¼Œå¯ä»¥ç†è§£ï¼Œå‡ºå»æµªï¼Œ
ä¸ºä»€ä¹ˆå‘¨æ—¥å¤§å®¶éƒ½å­¦æœºå™¨å­¦ä¹ ï¼Œä¹Ÿè®¸å’Œyoutubeçš„æ¨èæœºåˆ¶æœ‰å…³ï¼Œä¸€åˆ°å‘¨äº”ã€å…­å°±ä¸æ¨èç»™å¤§å®¶æœºå™¨å­¦ä¹ çš„è§†é¢‘ï¼Œæä¸æ‡‚
æ€»ä¹‹ï¼Œå‘ç°äº†è¿™ç§å‘¨æœŸæ€§çš„è§„å¾‹åï¼Œå°±å¯ä»¥æ”¹è¿›æ¨¡å‹ã€‚

å¯¹æ¨¡å‹çš„æ”¹è¿›å¾€å¾€æ¥è‡ªäºä½ å¯¹è¿™ä¸ªé—®é¢˜çš„ç†è§£ã€‚å³domain knowledge

ä¸€å¼€å§‹æˆ‘ä»¬å¯¹é—®é¢˜å®Œå…¨ä¸ç†è§£çš„æ—¶å€™ï¼Œå°±èƒ¡ä¹±å†™ä¸ª$y=b+wx_1$ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬è§‚å¯ŸçœŸå®æ•°æ®åï¼Œå¾—åˆ°ä¸€ä¸ªç»“è®ºï¼šæ¯éš”ä¸ƒå¤©æœ‰ä¸ªå¾ªç¯ï¼Œæ‰€ä»¥åº”è¯¥æŠŠå‰ä¸ƒå¤©çš„è§‚çœ‹äººæ¬¡éƒ½åˆ—å…¥è€ƒè™‘ã€‚å†™å‡ºå¦‚ä¸‹æ¨¡å‹ï¼š
$$
y=b+\sum_{j=1}^{7}{w_jx_j}
$$

ä¸Šé¢è€ƒè™‘äº†å‰7å¤©ï¼Œå¦‚æœè€ƒè™‘æ›´å¤šä¼šæ€æ ·å‘¢ï¼Ÿ
$$
y=b+\sum_{j=1}^{28}{w_jx_j}
$$

![Screen Shot 2021-12-29 at 3.49.12 PM](https://raw.githubusercontent.com/lunnche/picgo-image/main/Screen%20Shot%202021-12-29%20at%203.49.12%20PM.png)

ä¸Šå›¾ä¸ºè€ƒè™‘ä¸æ–­å¢åŠ å¤©æ•°ï¼Œå¯¹Lossçš„å½±å“ï¼Œå¯ä»¥çœ‹åˆ°è€ƒè™‘è¶Šå¤šçš„å¤©ï¼ŒLossè¶Šå°ï¼Œä½†ä»28å¤©å¢åŠ åˆ°56å¤©ï¼Œå¯¹äºé¢„æµ‹æœªæ¥å·²æ— æé«˜ï¼Œ$L'$ä¿æŒä¸º0.46k  

ä¸Šè¿°çš„æ¨¡å‹éƒ½æ˜¯featureä¹˜ä¸ŠweightåŠ ä¸Šbiasï¼Œè¿™ç±»æ¨¡å‹éƒ½å«åšlinear models  

linear models are too simple... we need more sophisticated models.  
ä¹Ÿè®¸x1å’Œyä¹‹é—´æœ‰å¤æ‚çš„å…³ç³»ï¼Œä½†linear modelsæ°¸è¿œåªèƒ½è¡¨å¾ä¸€æ¡ç›´çº¿ï¼Œéšç€x1è¶Šæ¥è¶Šé«˜ï¼Œyå°±ç†åº”è¶Šæ¥è¶Šå¤§ï¼Œæ”¹å˜wå’Œbåªèƒ½è°ƒæ•´æ–œç‡å’Œyå‘¨æˆªè·ï¼Œä¸ç®¡ä½ æ€ä¹ˆæ‘†å¼„wå’Œbï¼Œæ°¸è¿œä¹Ÿé€ ä¸å‡ºç±»ä¼¼çº¢è‰²çº¿è¿™ç§ä½“ç°ç‰©æå¿…åè§„å¾‹çš„æ›²çº¿  
Linear models have severe limitation   <b> Model Bias </b>

![Screen Shot 2021-12-29 at 4.00.13 PM](https://raw.githubusercontent.com/lunnche/picgo-image/main/Screen%20Shot%202021-12-29%20at%204.00.13%20PM.png)

We need a more flexible model!  

æ€ä¹ˆåšå‡ºçº¢è‰²çº¿è¿™æ ·çš„modelå‘¢

è§‚å¯Ÿå‘ç°ï¼š
<font color='red'>red curve</font>= constant + sum of a set of ![Screen Shot 2021-12-29 at 4.05.06 PM](https://raw.githubusercontent.com/lunnche/picgo-image/main/Screen%20Shot%202021-12-29%20at%204.05.06%20PM.png)


çº¢è‰²æ›²çº¿å¯è§†åšå¸¸é‡+ä¸€ç¾¤è“è‰²å›¾åƒçš„ç»“æœï¼Œè“è‰²å›¾åƒçš„ç‰¹ç‚¹æ˜¯ï¼š
å½“xè½´çš„å€¼å°äºæŸä¸€ä¸ªthreshholdçš„æ—¶å€™ï¼Œå®ƒæ˜¯ä¸€ä¸ªå®šå€¼ï¼Œå¤§äºå¦ä¸€ä¸ªthreshholdçš„æ—¶å€™ï¼Œåˆæ˜¯å¦ä¸€ä¸ªå®šå€¼ï¼Œä¸­é—´æœ‰ä¸€ä¸ªæ–œå¡ï¼Œ

å¸¸æ•°é¡¹constantå–å†³äºå›¾åƒå’Œyè½´çš„äº¤ç‚¹

æ€ä¹ˆå¾€ä¸ŠåŠ è“è‰²å›¾åƒå‘¢ï¼Œå’Œçº¢çº¿åŒèµ·ç‚¹ï¼Œæ–œå¡çš„ç»ˆç‚¹è®¾åœ¨ç¬¬ä¸€ä¸ªè½¬è§’å¤„ï¼Œä¿æŒè“è‰²å›¾åƒå’Œçº¢çº¿çš„æ–œç‡ä¸€æ ·ï¼Œ0çº¿+1çº¿å¯å¾—çº¢çº¿åœ¨ç¬¬ä¸€ä¸ªè½¬æŠ˜ç‚¹ä¹‹å‰çš„éƒ¨åˆ†  

æ¥ä¸‹æ¥å†åŠ è“è‰²çº¿2ï¼Œ0çº¿+1çº¿+2çº¿å¯å¾—çº¢çº¿ç¬¬äºŒä¸ªè½¬æŠ˜ç‚¹ä¹‹å‰çš„éƒ¨åˆ†ã€‚  

åŒç†åŠ çº¿3 ![Screen Shot 2021-12-29 at 4.20.31 PM](https://raw.githubusercontent.com/lunnche/picgo-image/main/Screen%20Shot%202021-12-29%20at%204.20.31%20PM.png)



![Screen Shot 2021-12-29 at 4.23.16 PM](https://raw.githubusercontent.com/lunnche/picgo-image/main/Screen%20Shot%202021-12-29%20at%204.23.16%20PM.png)

å³ä½¿xå’Œyçš„å…³ç³»ï¼Œä¸æ˜¯Piecewise Linearçš„Curvesï¼Œå¯ä»¥å…ˆåœ¨æ›²çº¿ä¸Šå–ä¸€äº›ç‚¹ï¼Œå†æŠŠè¿™äº›ç‚¹è¿èµ·æ¥ï¼Œå˜æˆä¸€ä¸ªpiecewise linear çš„curvesï¼Œç‚¹å–å¾—è¶Šå¤šï¼Œå–çš„ä½ç½®è¶Šåˆé€‚ï¼Œå°±è¶Šèƒ½é€¼è¿‘åŸæ¥çš„æ›²çº¿ã€‚

![Screen Shot 2021-12-29 at 4.29.40 PM](https://raw.githubusercontent.com/lunnche/picgo-image/main/Screen%20Shot%202021-12-29%20at%204.29.40%20PM.png)

bç«™å¼¹å¹•è¯´ï¼š
å¤šæ¬¡æ ·æ¡æ’å€¼
æ¯ä¸ªè“è‰²functionå°±æ˜¯ä¸€ä¸ªç¥ç»å…ƒï¼Ÿ  

è¿™ä¸ªè“è‰²functionï¼Œå®ƒçš„å¼å­ï¼Œè¦æ€ä¹ˆæŠŠå®ƒå†™å‡ºæ¥å‘¢ï¼Ÿ
ç›´æ¥å†™ä¹Ÿè®¸æ²¡é‚£ä¹ˆå®¹æ˜“ï¼Œä½†æ˜¯ä½ å¯ä»¥ç”¨ä¸€æ¡æ›²çº¿æ¥ç†è§£å®ƒï¼Œç”¨sigmoidçš„function
$$
\begin{aligned}
y&=c\frac{1}{1+e^{-(b+wx_1)}} \\
 &=c\,sigmoid(b+wx_1)
\end{aligned}
$$

xè¶‹äºæ— ç©·å¤§æ—¶ï¼Œæ›²çº¿ä¼šæ”¶æ•›åœ¨é«˜åº¦æ˜¯cçš„åœ°æ–¹  
xè¶‹äºæ— ç©·å°æ—¶ï¼Œæ›²çº¿ä¼šè¶‹äº0  

sigmoidï¼šç¡¬ç¿»æˆä¸­æ–‡ï¼Œå°±æ˜¯â€œså‹çš„â€

å¯ä»¥ç”¨sigmoidå»é€¼è¿‘è“è‰²functionï¼Œæ‰€ä»¥è“è‰²functionä¹Ÿå«åšHard Sigmoidã€‚

![Screen Shot 2021-12-30 at 11.12.13 AM](https://raw.githubusercontent.com/lunnche/picgo-image/main/Screen%20Shot%202021-12-30%20at%2011.12.13%20AM.png)

å„ç§å„æ ·çš„sigmoidï¼Œæ˜¯é€šè¿‡è°ƒæ•´bã€wã€cæ¥å¾—åˆ°çš„

![Screen Shot 2021-12-30 at 11.15.30 AM](https://raw.githubusercontent.com/lunnche/picgo-image/main/Screen%20Shot%202021-12-30%20at%2011.15.30%20AM.png)

æ‰€ä»¥ï¼ŒçŸ¥é“ä¸åŒçš„è“è‰²functionï¼ˆç”¨sigmoidè¿‘ä¼¼ï¼‰ï¼ŒæŠŠå®ƒä»¬å èµ·æ¥ï¼Œå°±æ„æˆäº†çº¢è‰²çš„Piecewise Linear Curves,å°±å¯ä»¥å»é€¼è¿‘å„å¼å„æ ·çš„ä¸åŒçš„Continuous Functionã€‚  
æ‰€ä»¥ï¼Œåˆ°æ­¤å¤„ï¼Œæˆ‘ä»¬å·²ç»æœ‰èƒ½åŠ›å†™å‡ºä¸€ä¸ªæœ‰å¼¹æ€§çš„æœ‰æœªçŸ¥å‚æ•°çš„function

![Screen Shot 2021-12-30 at 11.22.07 AM](https://raw.githubusercontent.com/lunnche/picgo-image/main/Screen%20Shot%202021-12-30%20at%2011.22.07%20AM.png)

# New Model: More Features

$$
y=b+wx_1\\
\downarrow \\
y=b+\sum_{i}c_i\,sigmoid(b_i+w_ix_1)\\
\\
y=b+\sum_jw_jx_j \ \ \ \ è€ƒè™‘å¤šä¸ªfeature\\
\downarrow \\
y=b+\sum_ic_i\,sigmoid(b_i+\sum_jw_{ij}x_j)
$$

<hr>

ä¸Šå¼å¥½å¤æ‚ï¼Œæ¥ç†è§£ä¸‹ï¼š
é¦–å…ˆå‡è®¾åªæœ‰ä¸‰ä¸ªfeature,å³j:1,2,3ï¼Œåªè€ƒè™‘å‰é¢ä¸‰å¤©çš„case
jæ˜¯number of features
x1:ä¸€å¤©å‰çš„è§‚çœ‹äººæ•°
x2:ä¸¤å¤©å‰çš„è§‚çœ‹äººæ•°
x3:ä¸‰å¤©å‰çš„è§‚çœ‹äººæ•°

iæ˜¯ä»€ä¹ˆï¼Œæ¯ä¸€ä¸ªiä»£è¡¨ä¸€ä¸ªè“è‰²function,æ¯ä¸€ä¸ªè“è‰²functionéƒ½ç”¨ä¸€ä¸ªsigmoid functionæ¥è¿‘ä¼¼å®ƒã€‚æ‰€ä»¥æ¯ä¸€ä¸ªiéƒ½ä»£è¡¨äº†ä¸€ä¸ªsigmoid function



$$
y = b+\sum_jc_i\,sigmoid(b_i+\sum_jw_{ij}x_j)\ \ \ j:1,2,3
$$

![Screen Shot 2021-12-30 at 2.17.10 PM](https://raw.githubusercontent.com/lunnche/picgo-image/main/Screen%20Shot%202021-12-30%20at%202.17.10%20PM.png)

é‚£è¿™ä¸ªx1 x2 x3 å’Œ r1 r2 r3 ä»€ä¹ˆå…³ç³»å‘¢  
å¯ä»¥ç”¨çŸ©é˜µå’Œå‘é‡ç›¸ä¹˜çš„æ–¹æ³•å†™ä¸€ä¸ªæ¯”è¾ƒç®€å•çš„ç®€æ´çš„å†™æ³•  

$$
y=b+
\sum_ic_i\,sigmoid(b_i+\sum_jw_{ij}x_j) \ \ \ \ i:1,2,3\ \ \ \ j:1,2,3
$$
æ‹¬å·ä¸­çš„
$$
b_i+\sum_jw_{ij}x_j
$$
è®°ä¸ºrï¼Œåˆ™ï¼š
$$
r_1=b_1+w_{11}x_1+w_{12}x_2+w_{13}x_3\\
r_2=b_2+w_{21}x_1+w_{22}x_2+w_{23}x_3\\
r_3=b_3+w_{31}x_1+w_{32}x_2+w_{33}x_3\\
\downarrow\\

\left[
\begin{matrix}
r_1\\
r_2\\
r_3
\end{matrix}
\right]
=
\left[
\begin{matrix}
b_1\\
b_2\\
b_3
\end{matrix}
\right]
+\left[
\begin{matrix}
w_{11}&w_{12}&w_{13}\\
w_{21}&w_{22}&w_{23}\\
w_{31}&w_{32}&w_{33}
\end{matrix}
\right]
\left[
\begin{matrix}
x_1\\
x_2\\
x_3
\end{matrix}
\right]
\\
\downarrow\\
r=b+Wx
$$

ç„¶åè¿™äº›rå†é€šè¿‡sigmoid function å¾—åˆ°a
$$
a_i=\,sigmoid(r_i)=
\frac1{1+e^{-r_i}}
$$
å³
$$
a=\sigma(r)\\
\downarrow\\
y=b+c^Ta
$$

![Screen Shot 2021-12-30 at 2.58.44 PM](https://raw.githubusercontent.com/lunnche/picgo-image/main/Screen%20Shot%202021-12-30%20at%202.58.44%20PM.png)

æœ€ç»ˆï¼š
$$
y=b+c^T
\sigma(b+Wx)
$$
<font color="red">æ³¨æ„ä¸Šé¢ä¸¤ä¸ªbä¸ä¸€æ ·ï¼Œå·¦è¾¹æ˜¯æ•°å€¼ï¼Œå³è¾¹æ˜¯å‘é‡ï¼Œä¸è¯¥ç”¨åŒä¸€ä¸ªå­—æ¯</font>


æ¥æ˜ç¡®ä¸‹å„å‚æ•°åˆ°åº•æ˜¯ä»€ä¹ˆï¼š

![Screen Shot 2021-12-30 at 3.25.35 PM](https://raw.githubusercontent.com/lunnche/picgo-image/main/Screen%20Shot%202021-12-30%20at%203.25.35%20PM.png)

ä¸€äº›é—®é¢˜ï¼š

æš´åŠ›æœç´¢:ç³»ç»Ÿåœ°æšä¸¾è§£å†³æ–¹æ¡ˆçš„æ‰€æœ‰å¯èƒ½çš„å€™é€‰é¡¹ï¼Œä»¥åŠæ£€æŸ¥æ¯ä¸ªå€™é€‰é¡¹æ˜¯å¦ç¬¦åˆé—®é¢˜çš„æè¿°ã€‚
æœªçŸ¥å‚æ•°åªæœ‰w,bçš„æƒ…å†µï¼Œå¯ä»¥ç”¨æš´åŠ›æœç´¢ï¼Œä½†éšç€é—®é¢˜è§„æ¨¡çš„å¢å¤§ï¼Œç©·ä¸¾æ‰€æœ‰å¯èƒ½æ˜¯ä¸ç°å®çš„ï¼Œè¦ç”¨æ¢¯åº¦ä¸‹é™ã€‚  

sigmoidè¶Šå¤šï¼Œä½ å¯ä»¥äº§ç”Ÿçš„piecewise linear functionå°±è¶Šå¤æ‚ï¼Œ
è¿™ä¸ªä¾‹å­é‡Œinput featureæ˜¯3ä¸ªï¼Œsigmoidä¹Ÿæ˜¯3ä¸ªï¼Œè¿™åªæ˜¯å·§åˆï¼Œä¸å¿…ç›¸åŒ  

hard sigmoidçš„functionæ¯”è¾ƒéš¾å†™ï¼Œæ‰€ä»¥ç”¨sigmoidï¼Œå¦‚æœä½ èƒ½å†™å‡ºæ¥ï¼Œç”¨hard sigmoidä¹Ÿå¯ä»¥ã€‚  

<hr>
ok,ç°åœ¨æˆ‘ä»¬æœ‰äº†æ–°çš„function with unkonwns
æ¥ä¸‹æ¥å¤„ç†Loss
ç°åœ¨Lossæ˜¯thetaçš„å‡½æ•°ï¼š

$$
L(\theta)
$$

ç»™å®šæŸä¸€ç»„
$$
w,b,c^T,b
$$
çš„å€¼

$$
y=b+c^T\sigma(b+Wx)\\
\\
\widehat{y}\ \ \ label
\\
\\
e=\left|y-\widehat{y}\right| \\
\\
\\

Loss:\ \ \ L=\frac1N\sum_ne_n
$$

<hr>

Optimization of New Model
$$
\theta^*=\mathop{\arg\min}_{\theta}L\ \ \ \ \ \ \ \ \theta=
\left[
\begin{matrix}
\theta_1\\
\theta_2\\
\theta_3\\
\vdots
\end{matrix}
\right]
$$

* (Randomly)Pick initial values  $\theta^0$


$$
g=
\left[
\begin{matrix}
\frac{\partial{L}}{\partial{\theta_1}}|_{\theta=\theta^0}\\
\frac{\partial{L}}{\partial{\theta_2}}|_{\theta=\theta^0}\\
\vdots
\end{matrix}
\right]
$$

gå³gradient

$$
g=\nabla L(\theta^0)
$$

è¿™ä¸ªå€’ä¸‰è§’çš„æ„æ€å°±æ˜¯ï¼ŒæŠŠæ‰€æœ‰å‚æ•°  $\theta$ é€šé€šæ‹¿å»å¯¹Lä½œå¾®åˆ†
åè¾¹æ”¾  $\theta^0$ çš„æ„æ€æ˜¯ï¼Œç®—å¾®åˆ†çš„ä½ç½®æ˜¯åœ¨  $\theta$ ç­‰äº  $\theta^0$ çš„åœ°æ–¹

ç®—å‡ºgradient åï¼Œæ¥ä¸‹æ¥updateæˆ‘ä»¬çš„å‚æ•°

$$
\left[
\begin{matrix}
\theta_1^1\\
\theta_2^1\\
\vdots
\end{matrix}
\right]
\leftarrow
\left[
\begin{matrix}
\theta_1^0\\
\theta_2^0\\
\vdots
\end{matrix}
\right]-
\left[
\begin{matrix}
\eta\frac{\partial{L}}{\partial{\theta_1}}|_{\theta=\theta^0}\\
\eta\frac{\partial{L}}{\partial{\theta_2}}|_{\theta=\theta^0}\\
\vdots
\end{matrix}
\right]
$$

ä¸Šå¼ç®€å†™ä¸ºï¼š
$$
\theta^1 \leftarrow \theta^0 - \eta g
$$

* Compute gradient  $g=\nabla L(\theta^0)$  
$$
\theta^1 \leftarrow \theta^0 - \eta g
$$
* Compute gradient  $g=\nabla L(\theta^1)$
$$
\theta^2 \leftarrow \theta^1 - \eta g
$$
* Compute gradient  $g=\nabla L(\theta^2)$
$$
\theta^3 \leftarrow \theta^2 - \eta g
$$


ç…§æ­¤åšä¸‹å»ï¼Œç›´åˆ°ä¸æƒ³åšäº†ï¼Œæˆ–è€…ç›´åˆ°gç®—å‡ºæ¥æ˜¯0å‘é‡ (Zero Vector)ï¼Œä¸è¿‡
åœ¨å®é™…æ“ä½œä¸­å‡ ä¹ä¸å¤ªå¯èƒ½ä½œå‡ºGradientæ˜¯0å‘é‡çš„ç»“æœï¼Œé€šå¸¸ä½ åœä¸‹æ¥åªæ˜¯å› ä¸ºä½ ä¸æƒ³åšäº†ã€‚  

å®é™…æ“ä½œä¸­ï¼Œæˆ‘ä»¬è¿™æ ·åšgradient descentï¼š
1  æœ‰Nç¬”èµ„æ–™ï¼ŒæŠŠå®ƒåˆ†æˆä¸€ä¸ªä¸ªbatchï¼Œæ€ä¹ˆåˆ†ï¼Ÿéšæœºåˆ†å°±å¥½
2  åˆ†å®Œåæ¯ä¸ªbatché‡Œæœ‰Bç¬”èµ„æ–™
3  æœ¬æ¥æ˜¯æŠŠæ‰€æœ‰çš„Dataæ‹¿å‡ºæ¥ç®—ä¸€ä¸ªLossï¼ˆLï¼‰ï¼Œä½†ç°åœ¨æˆ‘ä»¬åªæ‹¿å‡ºç¬¬ä¸€ä¸ªbatché‡Œçš„dataå‡ºæ¥ç®—ä¸€ä¸ªLossï¼ˆ$L^1$ï¼‰
4  è¯•æƒ³ï¼Œå‡è®¾è¿™ä¸ªBå¤Ÿå¤§ï¼Œä¹Ÿè®¸Lè·Ÿ$L^1$å¾ˆæ¥è¿‘ä¹Ÿè¯´ä¸å®š
5  å®ä½œä¸­ï¼Œä¼šå…ˆé€‰ä¸€ä¸ªbatchï¼Œç”¨è¿™ä¸ªbatchæ¥ç®—$L^1$ï¼Œç”¨è¿™ä¸ª$L^1$æ¥ç®—gradient:$g=\nabla L^1(\theta^0)$ï¼Œç”¨è¿™ä¸ªgradientæ¥æ›´æ–°å‚æ•°ï¼š
$$
\theta^1 \leftarrow \theta^0 - \eta g
$$
6  æ¥ä¸‹æ¥ï¼Œå†é€‰ä¸‹ä¸€ä¸ªbatchç®—å‡º$L^2$,æ ¹æ®$L^2$ç®—å‡ºgradient $g=\nabla L^2(\theta^1)$ï¼Œå†æ›´æ–°å‚æ•°ï¼š
$$
\theta^2 \leftarrow \theta^1 - \eta g
$$
7  å†å–ä¸‹ä¸€ä¸ªbatchç®—å‡º$L^3$ï¼Œæ ¹æ®$L^3$ç®—å‡ºgradientï¼Œ$g=\nabla L^3(\theta^2)$, å†æ›´æ–°å‚æ•°

$$
\theta^3 \leftarrow \theta^2 - \eta g
$$

8 æ‰€ä»¥æˆ‘ä»¬ä¸æ˜¯æ‹¿Læ¥ç®—gradientï¼Œå®é™…ä¸Šæ˜¯æ‹¿ä¸€ä¸ªbatchç®—å‡ºæ¥çš„$L^1,L^2,L^3$æ¥è®¡ç®—gradient

9 æŠŠæ‰€æœ‰batchéƒ½çœ‹è¿‡ä¸€æ¬¡ï¼Œå«åšä¸€ä¸ªEpochï¼Œæ¯ä¸€æ¬¡æ›´æ–°å‚æ•°å«åšä¸€æ¬¡Updateï¼Œ
    1 epoch = see all the batches once  

10 è‡³äºä¸ºä»€ä¹ˆè¦åˆ†ä¸€ä¸ªä¸ªbatchï¼Œä¸‹å‘¨å†è®²nice

![Screen Shot 2021-12-31 at 9.26.42 AM](https://raw.githubusercontent.com/lunnche/picgo-image/main/Screen%20Shot%202021-12-31%20at%209.26.42%20AM.png)

ä¸ºäº†æ›´å¥½åœ°åŒºåˆ†epochå’Œupdateï¼Œè¿™é‡Œä¸¾ä¸€ä¸ªæ —å­ğŸŒ°
Example 1:
* 10000 examples (N=10000)
* Batch size is 10 (B=10)
How many update in 1 epoch?  (epochå°±å¦‚åŒæ¸¸æˆé‡Œçš„å‘¨ç›®ï¼‰
                1000 updates 
æ‰€ä»¥ä¸€ä¸ªepochå¹¶ä¸æ˜¯æ›´æ–°å‚æ•°ä¸€æ¬¡ï¼Œä¸Šæ —ä¸€ä¸ªepochæ›´æ–°å‚æ•°1000æ¬¡  

Example 2
* 1000 examples (N=1000)
* Batch size is 100 (B=100) ï¼ˆBatch sizeçš„å¤§å°ä¹Ÿæ˜¯äººä¸ºå†³å®šçš„ï¼Œä¹Ÿæ˜¯hyper parameterï¼‰
<hr>
æ’å…¥ï¼šæ‰€ä»¥åˆ°ç›®å‰ä¸ºæ­¢éƒ½æœ‰å•¥æ˜¯hyper parameter:  <br>
learning rate $\eta$ <br>
å‡ ä¸ªsigmoid <br>
batch size <br>
<hr>
How many update in 1 epoch
                 10 updates

æ‰€ä»¥å¦‚æœæœ‰äººè·Ÿä½ è¯´åšäº†ä¸€ä¸ªepochçš„è®­ç»ƒï¼Œä½ å…¶å®å¹¶ä¸çŸ¥é“ä»–æ›´æ–°äº†å‡ æ¬¡å‚æ•°ã€‚æ‹’ç»äºæ€»æ ·æœ¬æ•°å’Œbatch sizeã€‚

æˆ‘ä»¬è¿˜å¯ä»¥å¯¹æ¨¡å‹åšæ›´å¤šçš„å˜å½¢ï¼š

Sigmoid $\rightarrow$ ReLU

hard sigmoid ä¸å¥½å—ï¼Œä¸ºä»€ä¹ˆè¦æŠŠå®ƒæ¢æˆsoft sigmoid,ä¸ä¸€å®šè¦æ¢æˆsoft sigmoid è¿˜æœ‰å…¶ä»–é€‰æ‹©ã€‚
æ¯”å¦‚ï¼Œhard sigmoidå‡½æ•°æœ‰ç‚¹éš¾å†™å‡ºæ¥ï¼Œå…¶å®ä¹Ÿæ²¡æœ‰é‚£ä¹ˆéš¾ï¼Œå®ƒå¯ä»¥çœ‹ä½œæ˜¯ä¸¤ä¸ªRectified Linear Unitçš„åŠ åˆã€‚
Rectified Linear Unit:
$$
c\,max(0,b+wx_1)
$$
ä¸¤ä¸ªReLuå åŠ èµ·æ¥å°±å¯ä»¥å˜æˆhard sigmoid  

![Screen Shot 2021-12-31 at 9.56.15 AM](https://raw.githubusercontent.com/lunnche/picgo-image/main/Screen%20Shot%202021-12-31%20at%209.56.15%20AM.png)

æ‰€ä»¥ï¼Œå¯ä»¥æŠŠsigmoidæ¢æˆReLU
$$
Sigmoid \rightarrow ReLU \\
\\
y = b + \sum_ic_i\,sigmoid(b_i + \sum_jw_{ij}x_j)\\
\\
\downarrow
\\
y = b + \sum_{2i}c_i\,max(0,b_i + \sum_jw_{ij}x_j)
$$


![Screen Shot 2021-12-31 at 10.04.07 AM](https://raw.githubusercontent.com/lunnche/picgo-image/main/Screen%20Shot%202021-12-31%20at%2010.04.07%20AM.png)

ç±»ä¼¼sigmoid ReLU å«åš activation function æ¿€æ´»å‡½æ•°

sigmoid å’ŒReLU å“ªä¸ªæ›´å¥½ï¼Ÿ
ReLUæ›´å¥½ï¼Œåé¢è®²  

æ¥çœ‹çœ‹å®é™…ç»“æœï¼š100ä¸ªReLUå°±å¯ä»¥åˆ¶é€ æ¯”è¾ƒå¤æ‚çš„æ›²çº¿ï¼Œæ•ˆæœå°±æ˜¾ç°å‡ºæ¥äº†ï¼Œä½†1000ä¸ªReLUæ”¹è¿›å°±æ²¡æœ‰é‚£ä¹ˆå¤§äº†ï¼š

![Screen Shot 2021-12-31 at 10.08.54 AM](https://raw.githubusercontent.com/lunnche/picgo-image/main/Screen%20Shot%202021-12-31%20at%2010.08.54%20AM.png)

è¿˜å¯ä»¥æ€ä¹ˆæ”¹è¿›æˆ‘ä»¬çš„æ¨¡å‹å‘¢ï¼Œä¸¾ä¾‹æ¥è¯´ï¼Œå¦‚ä¸‹å›¾ï¼Œä¹‹å‰è¯´è¿‡ä»xåˆ°aåšçš„äº‹æƒ…æ˜¯ä»€ä¹ˆï¼Ÿæ˜¯æŠŠxä¹˜ä¸ŠwåŠ ä¸Šbï¼Œå†é€šè¿‡sigmoid functionï¼ˆé€šè¿‡ReLUä¹Ÿå¯ä»¥ï¼‰å¾—åˆ°a  
æˆ‘ä»¬å¯ä»¥æŠŠä¸Šé¢è¿™ä»¶äº‹åå¤å¤šåšå‡ æ¬¡ï¼Œxé€šè¿‡ä¸€è¿ä¸²è¿ç®—äº§ç”Ÿaï¼Œaé€šè¿‡ä¸€è¿ä¸²è¿ç®—äº§ç”Ÿa',å¯ä»¥è¿™æ ·åå¤å¤šåšå‡ æ¬¡  

é‚£ä¹ˆè¦åšå‡ æ¬¡ï¼Ÿè¿™ä¸ªåšå‡ æ¬¡åˆæ˜¯ä¸€ä¸ªhyper parameter  

![Screen Shot 2021-12-31 at 10.18.50 AM](https://raw.githubusercontent.com/lunnche/picgo-image/main/Screen%20Shot%202021-12-31%20at%2010.18.50%20AM.png)

Experimental Results  
* Loss for multiple hidden layers
    * 100 ReLU for each layer
    * input features are the no. of views in the past 56 days


![Screen Shot 2021-12-31 at 10.23.10 AM](https://raw.githubusercontent.com/lunnche/picgo-image/main/Screen%20Shot%202021-12-31%20at%2010.23.10%20AM.png)

![Screen Shot 2021-12-31 at 10.28.45 AM](https://raw.githubusercontent.com/lunnche/picgo-image/main/Screen%20Shot%202021-12-31%20at%2010.28.45%20AM.png)

çº¢åœˆä¸ºå•¥æ²¡æœ‰æŠ¥å‡ºä½å€¼ï¼Œé‚£å¤©æ˜¯é™¤å¤•ï¼Œä¼—æ‰€å‘¨çŸ¥ï¼Œè¿‡å¹´ä¸å­¦æœºå™¨å­¦ä¹ ï¼Œè€Œæ¨¡å‹ä¸äº†è§£é™¤å¤•æ˜¯ä¸ªä»€ä¹ˆç©æ„ï¼Œå®ƒåªæ‡‚æ¯56å¤©çš„å˜åŒ–è§„å¾‹ã€‚

å¥½äº†ï¼Œç°åœ¨æˆ‘ä»¬è¿˜ç¼ºäº†ä¸€ä¸ªä¸œè¥¿ï¼ša fancy name   
ç»‡å¸­è´©å±¥ä¹‹å¾’ï¼Œè¯´ä»–æ˜¯æ±‰å·¦å°†å†›å®œåŸäº­ä¾¯ä¸­å±±é–ç‹ä¹‹åï¼Œä¹Ÿå°±æ½®äº†èµ·æ¥ï¼Œ  
æ‰€ä»¥æˆ‘ä»¬çš„æ¨¡å‹ä¹Ÿéœ€è¦ä¸€ä¸ªå¥½åå­—  

è¿™äº›sigmoid ReLUå•Š å«åš Neuron ç¥ç»å…ƒï¼Œå¾ˆå¤šçš„Neuron ç»„æˆ Neural Networ ç¥ç»ç½‘ç»œ  

Neural Network 80 90 å¹´ä»£å°±æœ‰ è¢«ç©åˆ° è‡­å¤§è¡—  

ä¸ºäº†é‡æŒ¯ Neural Networkçš„é›„é£ï¼Œéœ€è¦èµ·ä¸ªæ–°çš„åå­—ï¼Œæœ‰å¾ˆå¤šhidden layer å°±å«åšDeep  $\rightarrow$ Deep Learning  

ç„¶åäººä»¬å°±å¼€å§‹æŠŠç±»ç¥ç»ç½‘ç»œè¶Šå è¶Šå¤šï¼Œè¶Šå è¶Šæ·±ï¼Œ

![Screen Shot 2021-12-31 at 10.49.24 AM](https://raw.githubusercontent.com/lunnche/picgo-image/main/Screen%20Shot%202021-12-31%20at%2010.49.24%20AM.png)

è¿™é‡Œæœ‰ä¸ªé—®é¢˜ï¼Œç”¨è¶³å¤Ÿå¤šçš„sigmoid æˆ–è€… ReLU æ’ä¸€æ’ï¼ˆ1 hidden layerï¼‰å°±å¯ä»¥é€¼è¿‘ä»»ä½•å¤æ‚çš„è¿ç»­å‡½æ•°ï¼Œæå¤šå±‚ï¼Œædeepçš„æ„ä¹‰ä½•åœ¨ï¼Ÿæ‰€ä»¥æœ‰äººè¯´deep learning åªæ˜¯ä¸ªå™±å¤´  
æŠŠsigmoid ReLUæ’ä¸€æ’ï¼Œæ„é€ ä¸€ä¸ªfat neural networkä¸è¡Œå—ï¼Œä¸ºå•¥è¦ædeep neural network?  ä»¥åå†è®²  

å¦ä¸€ä¸ªä¸ºé¢˜ï¼Œä¸ºä½•ä¸åšå¾—æ›´æ·±ï¼Ÿä¸Šä¾‹ä¸ºä½•åªæ3å±‚ï¼Œä¸ç¨¿100å±‚ï¼Ÿå› ä¸ºå‘ç°åˆ°4 layerçš„æ—¶å€™ï¼Œå·²çŸ¥æ•°æ®Lossè™½ç„¶ä»0.14kå‡å°‘ä¸º0.10kï¼Œä½†æœªçŸ¥æ•°æ®çš„Lossä»0.38kå¢åŠ åˆ°0.44k  
Better on training data,worse on unseen data  
è¿™å°±æ˜¯ overfitting  

æ‰€ä»¥ï¼Œä»¥ä¸Šå°±æ˜¯æ·±åº¦å­¦ä¹ çš„ä»‹ç»ï¼Œä»‹ç»çš„å½¢å¼æ¯”è¾ƒç‰¹æ®Š  
æƒ³çœ‹ä¸€èˆ¬å½¢å¼çš„ä»‹ç»ï¼š https://youtu.be/Dr-WRIEFefw  

æ·±åº¦å­¦ä¹ çš„è®­ç»ƒä¼šç”¨åˆ°ä¸€ä¸ªä¸œè¥¿å«åš backpropagation  
https://youtu.be/ibJpTrp5mcE  

p3 ç»“æŸ


